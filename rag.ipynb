{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4329e7ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import tempfile\n",
    "from langchain_community.document_loaders import PyPDFLoader, Docx2txtLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_nvidia_ai_endpoints import NVIDIAEmbeddings, ChatNVIDIA\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough,RunnableAssign\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from operator import itemgetter\n",
    "from pydantic import BaseModel, Field\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c170abc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Anaconda\\envs\\medibot\\Lib\\site-packages\\langchain_nvidia_ai_endpoints\\_common.py:198: UserWarning: An API key is required for the hosted NIM. This will become an error in the future.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_25708\\3149388274.py:5: DeprecationWarning: The 'max_tokens' parameter is deprecated and will be removed in a future version. Please use 'max_completion_tokens' instead.\n",
      "  llm = ChatNVIDIA(\n"
     ]
    }
   ],
   "source": [
    "embedder = NVIDIAEmbeddings(\n",
    "    model=\"nvidia/nv-embedqa-e5-v5\"\n",
    ")\n",
    "\n",
    "llm = ChatNVIDIA(\n",
    "    model=\"openai/gpt-oss-120b\", \n",
    "    temperature=0.1,\n",
    "    max_tokens=1024\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b269fa2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GuardrailOutput(BaseModel):\n",
    "    is_relevant: bool = Field(description=\"Is the question about the document context?\")\n",
    "    reasoning: str = Field(description=\"Brief reason for the decision\")\n",
    "    \n",
    "guardrail_system_prompt = \"\"\"\n",
    "You are a security filter for a Contract Assistant. \n",
    "Analyze the user's question and determine if it is related to contract analysis, \n",
    "legal documents, or general information retrieval from a document.\n",
    "\n",
    "If the question is unrelated (e.g., \"tell me a joke\", \"how is the weather\"), \n",
    "set is_relevant to false.\n",
    "Answer based strictly on the context below:\n",
    "        {context}\n",
    "\n",
    "        Question: {question}\n",
    "\"\"\"\n",
    "\n",
    "guardrail_llm = llm.with_structured_output(GuardrailOutput)\n",
    "\n",
    "\n",
    "guardrail_chain = guardrail_system_prompt | guardrail_llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ceebdacd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting docx2txt\n",
      "  Downloading docx2txt-0.9-py3-none-any.whl.metadata (529 bytes)\n",
      "Downloading docx2txt-0.9-py3-none-any.whl (4.0 kB)\n",
      "Installing collected packages: docx2txt\n",
      "Successfully installed docx2txt-0.9\n"
     ]
    }
   ],
   "source": [
    "!pip install docx2txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a4ef50f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_uploaded_file(file_path):\n",
    "    # Handle both PDF and DOCX\n",
    "    if file_path.endswith('.pdf'):\n",
    "        loader = PyPDFLoader(file_path)\n",
    "    elif file_path.endswith('.docx'):\n",
    "        loader = Docx2txtLoader(file_path)\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported file format.\")\n",
    "    \n",
    "    docs = loader.load()\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "    splits = text_splitter.split_documents(docs)\n",
    "    \n",
    "    # Vector store setup\n",
    "    vectorstore = Chroma.from_documents(\n",
    "        documents=splits, \n",
    "        embedding=embedder,\n",
    "        collection_name=\"temp_collection\"\n",
    "    )\n",
    "    return vectorstore.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61ec841d",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'path_to_user_file' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m os.path.exists(\u001b[43mpath_to_user_file\u001b[49m):\n\u001b[32m      2\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mProcessing PDF...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      3\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[31mNameError\u001b[39m: name 'path_to_user_file' is not defined"
     ]
    }
   ],
   "source": [
    "def get_rag_chain(retriever):\n",
    "    prompt = ChatPromptTemplate.from_template(\"\"\"\n",
    "    Answer strictly based on the context: {context}\n",
    "    Question: {question}\n",
    "    \"\"\")\n",
    "    \n",
    "    return (\n",
    "        {\"context\": retriever | (lambda docs: \"\\n\\n\".join(d.page_content for d in docs)), \n",
    "         \"question\": RunnablePassthrough()}\n",
    "        | prompt \n",
    "        | llm \n",
    "        | StrOutputParser()\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "medibot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
